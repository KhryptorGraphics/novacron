{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Design - {{experimentName}}\n",
        "\n",
        "**MLE-Star Stage 1: Model Design and Architecture**\n",
        "\n",
        "This notebook covers the model design phase of the MLE-Star methodology:\n",
        "- Problem definition and success metrics\n",
        "- Data exploration and understanding\n",
        "- Model architecture selection\n",
        "- Baseline model implementation\n",
        "\n",
        "**Framework:** {{framework}}\n",
        "\n",
        "**Date:** {{date}}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "\n",
        "# Set style for plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette('husl')\n",
        "\n",
        "# Configure display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "\n",
        "print(\"Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Load project configuration\n",
        "config_path = Path('../configs/config.yaml')\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "print(\"Project Configuration:\")\n",
        "print(f\"Experiment: {config['experiment']['name']}\")\n",
        "print(f\"Framework: {config['model']['framework']}\")\n",
        "print(f\"Model Type: {config['model']['type']}\")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(config['data']['random_seed'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Problem Definition\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Problem Statement\n",
        "Define your machine learning problem here:\n",
        "\n",
        "**Problem Type:** [Classification/Regression/Clustering/etc.]\n",
        "\n",
        "**Objective:** [What are you trying to predict or optimize?]\n",
        "\n",
        "**Success Metrics:** [How will you measure success?]\n",
        "- Primary metric: \n",
        "- Secondary metrics: \n",
        "\n",
        "**Business Impact:** [Why is this problem important?]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Define problem parameters\n",
        "PROBLEM_TYPE = \"classification\"  # classification, regression, clustering, etc.\n",
        "TARGET_VARIABLE = \"target\"       # name of target column\n",
        "FEATURE_COLUMNS = []             # list of feature column names\n",
        "\n",
        "# Success metrics\n",
        "PRIMARY_METRIC = \"accuracy\"      # primary evaluation metric\n",
        "SECONDARY_METRICS = [\"precision\", \"recall\", \"f1_score\"]\n",
        "\n",
        "print(f\"Problem Type: {PROBLEM_TYPE}\")\n",
        "print(f\"Target Variable: {TARGET_VARIABLE}\")\n",
        "print(f\"Primary Metric: {PRIMARY_METRIC}\")\n",
        "print(f\"Secondary Metrics: {SECONDARY_METRICS}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Loading and Exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Load data\n",
        "data_path = Path(config['data']['raw_data_path'])\n",
        "print(f\"Data path: {data_path}\")\n",
        "\n",
        "# TODO: Load your dataset\n",
        "# Example:\n",
        "# df = pd.read_csv(data_path / 'data.csv')\n",
        "# print(f\"Data shape: {df.shape}\")\n",
        "\n",
        "# For demonstration, create sample data\n",
        "n_samples = 1000\n",
        "n_features = 10\n",
        "\n",
        "# Generate synthetic data for demonstration\n",
        "X = np.random.randn(n_samples, n_features)\n",
        "y = (X[:, 0] + X[:, 1] + np.random.randn(n_samples) * 0.1 > 0).astype(int)\n",
        "\n",
        "# Create DataFrame\n",
        "feature_names = [f'feature_{i}' for i in range(n_features)]\n",
        "df = pd.DataFrame(X, columns=feature_names)\n",
        "df[TARGET_VARIABLE] = y\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Features: {feature_names[:5]}...\")  # show first 5 features\n",
        "print(f\"Target distribution:\\n{df[TARGET_VARIABLE].value_counts()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Basic data exploration\n",
        "print(\"Dataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nBasic Statistics:\")\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Visualize data distribution\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Target distribution\n",
        "df[TARGET_VARIABLE].hist(ax=axes[0, 0], bins=20)\n",
        "axes[0, 0].set_title('Target Distribution')\n",
        "axes[0, 0].set_xlabel(TARGET_VARIABLE)\n",
        "\n",
        "# Feature distributions (first few features)\n",
        "for i, feature in enumerate(feature_names[:3]):\n",
        "    row = (i + 1) // 2\n",
        "    col = (i + 1) % 2\n",
        "    df[feature].hist(ax=axes[row, col], bins=30, alpha=0.7)\n",
        "    axes[row, col].set_title(f'Distribution of {feature}')\n",
        "    axes[row, col].set_xlabel(feature)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Correlation analysis\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
        "            square=True, fmt='.2f')\n",
        "plt.title('Feature Correlation Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Show features most correlated with target\n",
        "target_corr = correlation_matrix[TARGET_VARIABLE].abs().sort_values(ascending=False)\n",
        "print(f\"Features most correlated with {TARGET_VARIABLE}:\")\n",
        "print(target_corr.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Architecture Selection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Framework-specific imports\n",
        "framework = config['model']['framework']\n",
        "\n",
        "if framework == 'pytorch':\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.optim as optim\n",
        "    from torch.utils.data import DataLoader, TensorDataset\n",
        "    print(f\"PyTorch version: {torch.__version__}\")\n",
        "    \n",
        "elif framework == 'tensorflow':\n",
        "    import tensorflow as tf\n",
        "    from tensorflow import keras\n",
        "    from tensorflow.keras import layers\n",
        "    print(f\"TensorFlow version: {tf.__version__}\")\n",
        "    \n",
        "elif framework == 'scikit-learn':\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.svm import SVC\n",
        "    from sklearn.metrics import classification_report, confusion_matrix\n",
        "    import sklearn\n",
        "    print(f\"Scikit-learn version: {sklearn.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Model architecture design based on framework\n",
        "def create_model_architecture():\n",
        "    \"\"\"Create model architecture based on framework\"\"\"\n",
        "    \n",
        "    if framework == 'pytorch':\n",
        "        class MLPModel(nn.Module):\n",
        "            def __init__(self, input_size, hidden_layers, output_size, dropout_rate=0.2):\n",
        "                super(MLPModel, self).__init__()\n",
        "                layers = []\n",
        "                \n",
        "                # Input layer\n",
        "                layers.append(nn.Linear(input_size, hidden_layers[0]))\n",
        "                layers.append(nn.ReLU())\n",
        "                layers.append(nn.Dropout(dropout_rate))\n",
        "                \n",
        "                # Hidden layers\n",
        "                for i in range(len(hidden_layers) - 1):\n",
        "                    layers.append(nn.Linear(hidden_layers[i], hidden_layers[i+1]))\n",
        "                    layers.append(nn.ReLU())\n",
        "                    layers.append(nn.Dropout(dropout_rate))\n",
        "                \n",
        "                # Output layer\n",
        "                layers.append(nn.Linear(hidden_layers[-1], output_size))\n",
        "                \n",
        "                self.model = nn.Sequential(*layers)\n",
        "            \n",
        "            def forward(self, x):\n",
        "                return self.model(x)\n",
        "        \n",
        "        input_size = len(feature_names)\n",
        "        hidden_layers = config['model']['hidden_layers']\n",
        "        output_size = len(df[TARGET_VARIABLE].unique())\n",
        "        \n",
        "        model = MLPModel(input_size, hidden_layers, output_size)\n",
        "        print(f\"PyTorch Model Architecture:\")\n",
        "        print(model)\n",
        "        \n",
        "    elif framework == 'tensorflow':\n",
        "        input_size = len(feature_names)\n",
        "        hidden_layers = config['model']['hidden_layers']\n",
        "        output_size = len(df[TARGET_VARIABLE].unique())\n",
        "        \n",
        "        model = keras.Sequential([\n",
        "            layers.Dense(hidden_layers[0], activation='relu', input_shape=(input_size,)),\n",
        "            layers.Dropout(0.2)\n",
        "        ])\n",
        "        \n",
        "        for hidden_size in hidden_layers[1:]:\n",
        "            model.add(layers.Dense(hidden_size, activation='relu'))\n",
        "            model.add(layers.Dropout(0.2))\n",
        "        \n",
        "        # Output layer\n",
        "        activation = 'sigmoid' if output_size == 2 else 'softmax'\n",
        "        model.add(layers.Dense(output_size, activation=activation))\n",
        "        \n",
        "        print(f\"TensorFlow Model Architecture:\")\n",
        "        model.summary()\n",
        "        \n",
        "    elif framework == 'scikit-learn':\n",
        "        # Define multiple model options\n",
        "        models = {\n",
        "            'Random Forest': RandomForestClassifier(\n",
        "                n_estimators=100, random_state=config['data']['random_seed']\n",
        "            ),\n",
        "            'Logistic Regression': LogisticRegression(\n",
        "                random_state=config['data']['random_seed']\n",
        "            ),\n",
        "            'SVM': SVC(\n",
        "                kernel='rbf', random_state=config['data']['random_seed']\n",
        "            )\n",
        "        }\n",
        "        \n",
        "        print(\"Scikit-learn Model Options:\")\n",
        "        for name, model in models.items():\n",
        "            print(f\"- {name}: {type(model).__name__}\")\n",
        "        \n",
        "        model = models  # Return all models for comparison\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Create model architecture\n",
        "model_architecture = create_model_architecture()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Baseline Model Implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Split data for baseline model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Prepare features and target\n",
        "X = df[feature_names].values\n",
        "y = df[TARGET_VARIABLE].values\n",
        "\n",
        "# Split data\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=config['data']['random_seed'], stratify=y\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=config['data']['random_seed'], stratify=y_temp\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train.shape}\")\n",
        "print(f\"Validation set: {X_val.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Features scaled successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Train and evaluate baseline models\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "def train_baseline_model():\n",
        "    \"\"\"Train baseline model based on framework\"\"\"\n",
        "    \n",
        "    if framework == 'scikit-learn':\n",
        "        results = {}\n",
        "        \n",
        "        for name, model in model_architecture.items():\n",
        "            print(f\"\\nTraining {name}...\")\n",
        "            \n",
        "            # Train model\n",
        "            model.fit(X_train_scaled, y_train)\n",
        "            \n",
        "            # Make predictions\n",
        "            train_pred = model.predict(X_train_scaled)\n",
        "            val_pred = model.predict(X_val_scaled)\n",
        "            \n",
        "            # Calculate metrics\n",
        "            train_acc = accuracy_score(y_train, train_pred)\n",
        "            val_acc = accuracy_score(y_val, val_pred)\n",
        "            \n",
        "            results[name] = {\n",
        "                'model': model,\n",
        "                'train_accuracy': train_acc,\n",
        "                'val_accuracy': val_acc,\n",
        "                'val_predictions': val_pred\n",
        "            }\n",
        "            \n",
        "            print(f\"Training Accuracy: {train_acc:.4f}\")\n",
        "            print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    else:\n",
        "        print(f\"Baseline training for {framework} will be implemented in training pipeline notebook\")\n",
        "        return None\n",
        "\n",
        "# Train baseline models\n",
        "baseline_results = train_baseline_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Evaluate baseline results\n",
        "if baseline_results:\n",
        "    print(\"\\nBaseline Model Comparison:\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    comparison_data = []\n",
        "    \n",
        "    for name, result in baseline_results.items():\n",
        "        comparison_data.append({\n",
        "            'Model': name,\n",
        "            'Train Accuracy': f\"{result['train_accuracy']:.4f}\",\n",
        "            'Val Accuracy': f\"{result['val_accuracy']:.4f}\",\n",
        "            'Overfitting': f\"{result['train_accuracy'] - result['val_accuracy']:.4f}\"\n",
        "        })\n",
        "    \n",
        "    comparison_df = pd.DataFrame(comparison_data)\n",
        "    print(comparison_df.to_string(index=False))\n",
        "    \n",
        "    # Find best model\n",
        "    best_model_name = max(baseline_results.keys(), \n",
        "                         key=lambda x: baseline_results[x]['val_accuracy'])\n",
        "    best_model = baseline_results[best_model_name]['model']\n",
        "    \n",
        "    print(f\"\\nBest baseline model: {best_model_name}\")\n",
        "    print(f\"Best validation accuracy: {baseline_results[best_model_name]['val_accuracy']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Detailed analysis of best model\n",
        "if baseline_results:\n",
        "    print(f\"\\nDetailed Analysis of {best_model_name}:\")\n",
        "    \n",
        "    val_pred = baseline_results[best_model_name]['val_predictions']\n",
        "    \n",
        "    # Classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_val, val_pred))\n",
        "    \n",
        "    # Confusion Matrix\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    cm = confusion_matrix(y_val, val_pred)\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix - {best_model_name}')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Design Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Create model design summary\n",
        "design_summary = {\n",
        "    'experiment_name': config['experiment']['name'],\n",
        "    'framework': framework,\n",
        "    'problem_type': PROBLEM_TYPE,\n",
        "    'target_variable': TARGET_VARIABLE,\n",
        "    'n_features': len(feature_names),\n",
        "    'n_samples': len(df),\n",
        "    'data_splits': {\n",
        "        'train': len(X_train),\n",
        "        'validation': len(X_val),\n",
        "        'test': len(X_test)\n",
        "    },\n",
        "    'primary_metric': PRIMARY_METRIC,\n",
        "    'secondary_metrics': SECONDARY_METRICS,\n",
        "    'baseline_performance': {},\n",
        "    'next_steps': [\n",
        "        'Implement full training pipeline',\n",
        "        'Perform hyperparameter tuning',\n",
        "        'Conduct thorough model evaluation',\n",
        "        'Implement systematic testing'\n",
        "    ]\n",
        "}\n",
        "\n",
        "if baseline_results:\n",
        "    design_summary['baseline_performance'] = {\n",
        "        name: {'val_accuracy': result['val_accuracy']}\n",
        "        for name, result in baseline_results.items()\n",
        "    }\n",
        "    design_summary['best_baseline'] = best_model_name\n",
        "\n",
        "print(\"Model Design Summary:\")\n",
        "print(yaml.dump(design_summary, default_flow_style=False))\n",
        "\n",
        "# Save design summary\n",
        "summary_path = Path('../outputs/reports/model_design_summary.yaml')\n",
        "summary_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "with open(summary_path, 'w') as f:\n",
        "    yaml.dump(design_summary, f, default_flow_style=False)\n",
        "\n",
        "print(f\"\\nModel design summary saved to: {summary_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Next Steps\n",
        "\n",
        "Based on the model design analysis, the recommended next steps are:\n",
        "\n",
        "1. **Learning Pipeline (Stage 2)**: Implement comprehensive data preprocessing and feature engineering\n",
        "2. **Evaluation Setup (Stage 3)**: Define detailed evaluation metrics and validation strategies\n",
        "3. **Systematic Testing (Stage 4)**: Create unit tests for model components\n",
        "4. **Training Optimization (Stage 5)**: Implement hyperparameter tuning and model optimization\n",
        "5. **Analysis Validation (Stage 6)**: Perform model interpretability and validation analysis\n",
        "6. **Refinement Deployment (Stage 7)**: Prepare final model for deployment\n",
        "\n",
        "**Key Insights from Model Design:**\n",
        "- Data shape and characteristics\n",
        "- Feature importance and correlations\n",
        "- Baseline model performance benchmarks\n",
        "- Framework-specific implementation considerations\n",
        "\n",
        "Continue to the next notebook: `02_training_pipeline.ipynb`\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}