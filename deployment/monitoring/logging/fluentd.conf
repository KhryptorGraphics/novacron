# Fluentd configuration for NovaCron log aggregation
<system>
  log_level info
  suppress_repeated_stacktrace true
  emit_error_log_interval 30s
  suppress_config_dump
  without_source
  workers 4
  root_dir /var/log/fluentd
</system>

# Input sources
<source>
  @type tail
  @id novacron_api_logs
  path /var/log/novacron/api/*.log
  pos_file /var/log/fluentd/api.log.pos
  tag novacron.api
  format json
  time_key timestamp
  time_format %Y-%m-%dT%H:%M:%S.%L%z
  keep_time_key true
  read_from_head true
  multiline_flush_interval 5s
  emit_unmatched_lines true
  <parse>
    @type json
    json_parser json
    key_name message
  </parse>
</source>

<source>
  @type tail
  @id novacron_vm_manager_logs
  path /var/log/novacron/vm-manager/*.log
  pos_file /var/log/fluentd/vm-manager.log.pos
  tag novacron.vm-manager
  format json
  time_key timestamp
  time_format %Y-%m-%dT%H:%M:%S.%L%z
  keep_time_key true
  read_from_head true
  <parse>
    @type json
  </parse>
</source>

<source>
  @type tail
  @id novacron_storage_logs
  path /var/log/novacron/storage/*.log
  pos_file /var/log/fluentd/storage.log.pos
  tag novacron.storage
  format json
  time_key timestamp
  time_format %Y-%m-%dT%H:%M:%S.%L%z
  keep_time_key true
  read_from_head true
  <parse>
    @type json
  </parse>
</source>

<source>
  @type tail
  @id novacron_network_logs
  path /var/log/novacron/network/*.log
  pos_file /var/log/fluentd/network.log.pos
  tag novacron.network
  format json
  time_key timestamp
  time_format %Y-%m-%dT%H:%M:%S.%L%z
  keep_time_key true
  read_from_head true
  <parse>
    @type json
  </parse>
</source>

# System logs
<source>
  @type systemd
  @id systemd_logs
  path /var/log/journal
  tag system.journal
  read_from_head true
  strip_underscores true
  <storage>
    @type local
    persistent true
    path /var/log/fluentd/systemd.pos
  </storage>
  <entry>
    field_map {"_SYSTEMD_UNIT": "unit", "_HOSTNAME": "hostname", "_PID": "pid"}
    fields_strip_underscores true
    fields_lowercase true
  </entry>
</source>

# Docker logs
<source>
  @type forward
  @id docker_logs
  port 24224
  bind 0.0.0.0
  tag docker.*
</source>

# Kubernetes logs (if applicable)
<source>
  @type kubernetes_audit
  @id kubernetes_audit
  audit_log_path /var/log/audit/audit.log
  pos_file /var/log/fluentd/audit.log.pos
  tag kubernetes.audit
  <parse>
    @type json
  </parse>
</source>

# Processing and filtering
<filter novacron.**>
  @type record_transformer
  @id add_novacron_metadata
  enable_ruby
  <record>
    hostname "#{Socket.gethostname}"
    environment "production"
    service_name ${tag_parts[1]}
    cluster "novacron-production"
    region "us-west-2"
    log_processed_at ${Time.now.iso8601}
  </record>
</filter>

# Parse structured logs and extract trace information
<filter novacron.**>
  @type parser
  @id extract_trace_info
  key_name message
  reserve_data true
  reserve_time true
  suppress_parse_error_log true
  <parse>
    @type regexp
    expression /trace_id=(?<trace_id>[a-f0-9]{32}) span_id=(?<span_id>[a-f0-9]{16})/
  </parse>
</filter>

# Security log processing
<filter novacron.api>
  @type grep
  @id security_events
  <regexp>
    key message
    pattern /(authentication|authorization|security|intrusion|attack)/i
  </regexp>
  <and>
    <regexp>
      key level
      pattern /(WARN|ERROR|FATAL)/i
    </regexp>
  </and>
</filter>

# Error log processing
<filter novacron.**>
  @type grep
  @id error_logs
  <regexp>
    key level
    pattern /(ERROR|FATAL)/i
  </regexp>
</filter>

# Performance metrics extraction
<filter novacron.**>
  @type parser
  @id extract_metrics
  key_name message
  reserve_data true
  suppress_parse_error_log true
  <parse>
    @type regexp
    expression /duration=(?<duration_ms>\d+)ms response_size=(?<response_size>\d+)/
  </parse>
</filter>

# Rate limiting for high-volume logs
<filter novacron.**>
  @type sampling
  @id rate_limit
  sampling_rate 10
  <matches>
    <match>
      key level
      pattern /DEBUG/
    </match>
  </matches>
</filter>

# Output configurations
<match novacron.api>
  @type copy
  <store>
    @type elasticsearch
    @id elasticsearch_api
    host elasticsearch
    port 9200
    logstash_format true
    logstash_prefix novacron-api
    logstash_dateformat %Y.%m.%d
    index_name novacron-api
    type_name _doc
    include_timestamp true
    reconnect_on_error true
    reload_on_failure true
    reload_connections false
    request_timeout 30s
    <buffer>
      @type file
      path /var/log/fluentd/api.buffer
      flush_mode interval
      flush_interval 10s
      flush_thread_count 2
      retry_forever true
      retry_max_interval 30
      chunk_limit_size 2M
      queue_limit_length 8
      overflow_action block
    </buffer>
  </store>
  
  # Send critical errors to Slack
  <store>
    @type slack
    @id slack_critical_api
    webhook_url "#{ENV['SLACK_WEBHOOK_URL']}"
    username "NovaCron Logs"
    icon_emoji ":warning:"
    channel "#ops-alerts"
    title "Critical API Error"
    message "API Error: %s\nHost: %s\nTrace: %s"
    message_keys level,hostname,trace_id
    flush_interval 60s
    <match>
      <regexp>
        key level
        pattern /ERROR|FATAL/
      </regexp>
    </match>
  </store>
</match>

<match novacron.vm-manager>
  @type elasticsearch
  @id elasticsearch_vm
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix novacron-vm
  logstash_dateformat %Y.%m.%d
  index_name novacron-vm
  type_name _doc
  include_timestamp true
  <buffer>
    @type file
    path /var/log/fluentd/vm.buffer
    flush_mode interval
    flush_interval 10s
    retry_forever true
    chunk_limit_size 2M
  </buffer>
</match>

<match novacron.storage>
  @type elasticsearch
  @id elasticsearch_storage
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix novacron-storage
  logstash_dateformat %Y.%m.%d
  index_name novacron-storage
  type_name _doc
  include_timestamp true
  <buffer>
    @type file
    path /var/log/fluentd/storage.buffer
    flush_mode interval
    flush_interval 10s
    retry_forever true
    chunk_limit_size 2M
  </buffer>
</match>

<match novacron.network>
  @type elasticsearch
  @id elasticsearch_network
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix novacron-network
  logstash_dateformat %Y.%m.%d
  index_name novacron-network
  type_name _doc
  include_timestamp true
  <buffer>
    @type file
    path /var/log/fluentd/network.buffer
    flush_mode interval
    flush_interval 10s
    retry_forever true
    chunk_limit_size 2M
  </buffer>
</match>

# Security logs to dedicated index with longer retention
<match security.**>
  @type elasticsearch
  @id elasticsearch_security
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix novacron-security
  logstash_dateformat %Y.%m.%d
  index_name novacron-security
  type_name _doc
  include_timestamp true
  <buffer>
    @type file
    path /var/log/fluentd/security.buffer
    flush_mode interval
    flush_interval 5s
    retry_forever true
    chunk_limit_size 1M
  </buffer>
</match>

# System logs
<match system.**>
  @type elasticsearch
  @id elasticsearch_system
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix novacron-system
  logstash_dateformat %Y.%m.%d
  index_name novacron-system
  type_name _doc
  include_timestamp true
  <buffer>
    @type file
    path /var/log/fluentd/system.buffer
    flush_mode interval
    flush_interval 30s
    retry_forever true
    chunk_limit_size 5M
  </buffer>
</match>

# Docker logs
<match docker.**>
  @type elasticsearch
  @id elasticsearch_docker
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix novacron-docker
  logstash_dateformat %Y.%m.%d
  index_name novacron-docker
  type_name _doc
  include_timestamp true
  <buffer>
    @type file
    path /var/log/fluentd/docker.buffer
    flush_mode interval
    flush_interval 15s
    retry_forever true
    chunk_limit_size 3M
  </buffer>
</match>

# Kubernetes audit logs
<match kubernetes.audit>
  @type elasticsearch
  @id elasticsearch_k8s_audit
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix novacron-k8s-audit
  logstash_dateformat %Y.%m.%d
  index_name novacron-k8s-audit
  type_name _doc
  include_timestamp true
  <buffer>
    @type file
    path /var/log/fluentd/k8s-audit.buffer
    flush_mode interval
    flush_interval 10s
    retry_forever true
    chunk_limit_size 2M
  </buffer>
</match>

# Error log aggregation and alerting
<match error.**>
  @type copy
  <store>
    @type elasticsearch
    @id elasticsearch_errors
    host elasticsearch
    port 9200
    logstash_format true
    logstash_prefix novacron-errors
    logstash_dateformat %Y.%m.%d
    index_name novacron-errors
    type_name _doc
    include_timestamp true
    <buffer>
      @type file
      path /var/log/fluentd/errors.buffer
      flush_mode interval
      flush_interval 5s
      retry_forever true
      chunk_limit_size 1M
    </buffer>
  </store>
  
  # Send errors to monitoring system
  <store>
    @type prometheus
    @id prometheus_error_metrics
    <metric>
      name fluentd_errors_total
      type counter
      desc Total number of errors processed by fluentd
      <labels>
        service ${service_name}
        level ${level}
        hostname ${hostname}
      </labels>
    </metric>
  </store>
</match>

# Catch-all for unmatched logs
<match **>
  @type elasticsearch
  @id elasticsearch_catchall
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix novacron-misc
  logstash_dateformat %Y.%m.%d
  index_name novacron-misc
  type_name _doc
  include_timestamp true
  suppress_type_name true
  <buffer>
    @type file
    path /var/log/fluentd/misc.buffer
    flush_mode interval
    flush_interval 60s
    retry_forever true
    chunk_limit_size 10M
    queue_limit_length 4
    overflow_action drop_oldest_chunk
  </buffer>
</match>

# Metrics output to Prometheus
<source>
  @type prometheus
  bind 0.0.0.0
  port 24231
  metrics_path /metrics
</source>

<source>
  @type prometheus_monitor
  @id prometheus_fluentd_monitor
  interval 10
  <labels>
    hostname ${hostname}
  </labels>
</source>